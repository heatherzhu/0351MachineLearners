{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\icy58\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data = np.array(data)\n",
    "\n",
    "labels = data[:,1]\n",
    "data = data[:,3]\n",
    "\n",
    "def filtering(text, stopwords = nltk.corpus.stopwords.words(\"english\")):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\S+\", \"\", text)\n",
    "    text = re.sub(r\"WWW\\S+\", \"\", text)\n",
    "    \n",
    "    text = text.split(\" \")\n",
    "    \n",
    "    filtered = \"\"\n",
    "    for i in range(len(text)):\n",
    "        if not (text[i] == '' or text[i] in stopwords):\n",
    "            filtered = (filtered + \" \" + text[i])\n",
    "            \n",
    "    return str(filtered)\n",
    "\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = filtering(data[i])\n",
    "\n",
    "data = np.reshape(data, (len(data),1))\n",
    "labels = np.reshape(labels, (len(labels),1))\n",
    "train = np.concatenate((data, labels),axis=1)\n",
    "\n",
    "train = train[:4000] #Modify based on how much memory your machine has (larger number = more running time but better results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worry'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"Dataset2.csv\")\n",
    "data2 = np.array(data2)\n",
    "\n",
    "labels2 = data2[:,1]\n",
    "data2 = data2[:,0]\n",
    "\n",
    "filtered_labels = []\n",
    "filtered_data = []\n",
    "\n",
    "for i in range(len(labels2)):\n",
    "    curr_label = labels2[i]\n",
    "    curr_label = str(curr_label)\n",
    "    label_arr = curr_label.split(\",\")\n",
    "    \n",
    "    for x in range(len(label_arr)):\n",
    "        filtered_labels.append(label_arr[x])\n",
    "        filtered_data.append(data2[i])\n",
    "        \n",
    "for i in range(len(filtered_data)):\n",
    "    filtered_data[i] = filtering(filtered_data[i])\n",
    "\n",
    "filtered_data = np.reshape(filtered_data, (len(filtered_data),1))\n",
    "filtered_labels = np.reshape(filtered_labels, (len(filtered_labels),1))\n",
    "train = np.concatenate((filtered_data, filtered_labels),axis=1)\n",
    "\n",
    "train = train[:5000] #Modify based on how much memory your machine has (larger number = more running time but better results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('text.txt', 'r')\n",
    "text_to_analyize = f.read()\n",
    "text_to_analyize = text_to_analyize.replace('\\n',\"\")\n",
    "text_to_analyize = text_to_analyize.replace(\"  \",\" \")\n",
    "text_to_analyize = text_to_analyize.replace(\"  \",\" \")\n",
    "text_to_analyize = text_to_analyize.replace(\"  \",\" \")\n",
    "text_to_analyize = text_to_analyize.replace(\"  \",\" \")\n",
    "text_to_analyize = text_to_analyize.strip()\n",
    "text_to_analyize = text_to_analyize.split(\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = np.zeros(28)\n",
    "overall_sentiment = 0\n",
    "s = SentimentIntensityAnalyzer()\n",
    "total = 0 \n",
    "chunks = 15\n",
    "for i in range(70):\n",
    "    total += 1\n",
    "    currstr = \"\"\n",
    "    for x in range(chunks):\n",
    "        currstr += text_to_analyize[i*5 + x]\n",
    "        overall_sentiment += s.polarity_scores(text_to_analyize[i*5 + x])[\"compound\"]\n",
    "    emotion = classifier.classify(currstr)\n",
    "    emotion = int(emotion)\n",
    "    values[emotion] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admiration Score: 0.0\n",
      "Amusement Score: 0.0\n",
      "Anger Score: 5.0\n",
      "Annoyance Score: 2.0\n",
      "Approval Score: 3.0\n",
      "Caring Score: 13.0\n",
      "Confusion Score: 9.0\n",
      "Curiosity Score: 3.0\n",
      "Desire Score: 0.0\n",
      "Disappointment Score: 1.0\n",
      "Disapproval Score: 3.0\n",
      "Disgust Score: 0.0\n",
      "Embarrassment Score: 0.0\n",
      "Excitement Score: 0.0\n",
      "Fear Score: 0.0\n",
      "Gratitude Score: 0.0\n",
      "Grief Score: 0.0\n",
      "Joy Score: 7.0\n",
      "Love Score: 1.0\n",
      "Nervousness Score: 0.0\n",
      "Optimism Score: 12.0\n",
      "Pride Score: 0.0\n",
      "Realization Score: 7.0\n",
      "Relief Score: 0.0\n",
      "Remorse Score: 0.0\n",
      "Sadness Score: 2.0\n",
      "Surprise Score: 2.0\n",
      "Neutral Score: 0.0\n",
      "Total:70\n",
      "0.03652266666666669\n"
     ]
    }
   ],
   "source": [
    "print(\"Admiration Score: \" + str(values[0]))\n",
    "print(\"Amusement Score: \" + str(values[1]))\n",
    "print(\"Anger Score: \" + str(values[2]))\n",
    "print(\"Annoyance Score: \" + str(values[3]))\n",
    "print(\"Approval Score: \" + str(values[4]))\n",
    "print(\"Caring Score: \" + str(values[5]))\n",
    "print(\"Confusion Score: \" + str(values[6]))\n",
    "print(\"Curiosity Score: \" + str(values[7]))\n",
    "print(\"Desire Score: \" + str(values[8]))\n",
    "print(\"Disappointment Score: \" + str(values[9]))\n",
    "print(\"Disapproval Score: \" + str(values[10]))\n",
    "print(\"Disgust Score: \" + str(values[11]))\n",
    "print(\"Embarrassment Score: \" + str(values[12]))\n",
    "print(\"Excitement Score: \" + str(values[13]))\n",
    "print(\"Fear Score: \" + str(values[14]))\n",
    "print(\"Gratitude Score: \" + str(values[15]))\n",
    "print(\"Grief Score: \" + str(values[16]))\n",
    "print(\"Joy Score: \" + str(values[17]))\n",
    "print(\"Love Score: \" + str(values[18]))\n",
    "print(\"Nervousness Score: \" + str(values[19]))\n",
    "print(\"Optimism Score: \" + str(values[20]))\n",
    "print(\"Pride Score: \" + str(values[21]))\n",
    "print(\"Realization Score: \" + str(values[22]))\n",
    "print(\"Relief Score: \" + str(values[23]))\n",
    "print(\"Remorse Score: \" + str(values[24]))\n",
    "print(\"Sadness Score: \" + str(values[25]))\n",
    "print(\"Surprise Score: \" + str(values[26]))\n",
    "print(\"Neutral Score: \" + str(values[27]))\n",
    "print(\"Total:\" + str(total))\n",
    "\n",
    "\n",
    "print(overall_sentiment/(total*chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
